{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/raaed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/raaed/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/raaed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "brnli_vectorizer = CountVectorizer(binary = True)\n",
    "\n",
    "add_one = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath) -> list[tuple]:\n",
    "    ham_data = []\n",
    "    spam_data = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(filepath):\n",
    "        for filename in filenames:\n",
    "            with open(os.path.join(dirpath,filename), encoding = 'iso-8859-1') as f:\n",
    "                if 'ham' in filename:\n",
    "                    ham_data.append(f.read())\n",
    "                elif 'spam' in filename:\n",
    "                    spam_data.append(f.read())\n",
    "    \n",
    "    # assign 1/0 to samples and combine data\n",
    "    positive_samples = [(email, 1) for email in ham_data]\n",
    "    negative_samples = [(email, 0) for email in spam_data]\n",
    "\n",
    "    all_samples = positive_samples + negative_samples\n",
    "    random.shuffle(all_samples)\n",
    "\n",
    "    #remove stop words and lemmatize dataset\n",
    "    filtered_dataset = []\n",
    "    for text, y in all_samples:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [word for word in words if word.lower() not in stop_words]\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        fil_text = \" \".join(words)\n",
    "        filtered_dataset.append((fil_text, y))\n",
    "    return filtered_dataset# [(text, 0), (text, 1)...] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path each of the datasets. Point to the directory containing the ham, spam directories - \n",
    "enron1_test = load_dataset('project1_datasets/enron1/test')\n",
    "enron1_train = load_dataset('project1_datasets/enron1 2/train')\n",
    "\n",
    "enron2_test = load_dataset('project1_datasets/test')\n",
    "enron2_train = load_dataset('project1_datasets/train')\n",
    "\n",
    "enron4_test = load_dataset('project1_datasets/enron4/test')\n",
    "enron4_train = load_dataset('project1_datasets/enron4 2/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the text data to bernoulli and bow models\n",
    "def convert_to_bow(dataset):\n",
    "    emails = [email for email, y in dataset]\n",
    "    c = [y for email, y in dataset]\n",
    "\n",
    "    bow_matrix = bow_vectorizer.fit_transform(emails)\n",
    "    return bow_matrix, np.array(c)\n",
    "\n",
    "\n",
    "def convert_to_bernoulli(dataset):\n",
    "    emails = [email for email, y in dataset]\n",
    "    c = [y for email, y in dataset]\n",
    "\n",
    "    brnli_matrix = brnli_vectorizer.fit_transform(emails)\n",
    "    return brnli_matrix, np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag Of Words datasets\n",
    "e1_Xtrain_bow, e1_ytrain_bow = convert_to_bow(enron1_train)\n",
    "e1_Xtest_bow, e1_ytest_bow = convert_to_bow(enron1_test)\n",
    "\n",
    "e2_Xtrain_bow, e2_ytrain_bow = convert_to_bow(enron2_train)\n",
    "e2_Xtest_bow, e2_ytest_bow = convert_to_bow(enron2_test)\n",
    "\n",
    "e4_Xtrain_bow, e4_ytrain_bow = convert_to_bow(enron4_train)\n",
    "e4_Xtest_bow, e4_ytest_bow = convert_to_bow(enron4_test)\n",
    "\n",
    "# Bernoulli datasets\n",
    "e1_Xtrain_bli, e1_ytrain_bli = convert_to_bernoulli(enron1_train)\n",
    "e1_Xtest_bli, e1_ytest_bli = convert_to_bernoulli(enron1_test)\n",
    "\n",
    "e2_Xtrain_bli, e2_ytrain_bli = convert_to_bernoulli(enron2_train)\n",
    "e2_Xtest_bli, e2_ytest_bli = convert_to_bernoulli(enron2_test)\n",
    "\n",
    "e4_Xtrain_bli, e4_ytrain_bli = convert_to_bernoulli(enron4_train)\n",
    "e4_Xtest_bli, e4_ytest_bli = convert_to_bernoulli(enron4_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def train(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = []\n",
    "        self.vocab = np.sum(X, axis = 0)\n",
    "        self.features = X.shape[1]\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            param_c = {}\n",
    "            param_c['prior'] = np.log(X_c.shape[0] / float(X.shape[0]))\n",
    "            param_c[\"word_count\"] = np.sum(X_c, axis = 0)\n",
    "            param_c['word_prob'] = np.log((param_c[\"word_count\"] + add_one) / (np.sum(param_c[\"word_count\"]) + X.shape[1]))\n",
    "            self.parameters.append(param_c)\n",
    "\n",
    "            \n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        for x in X:\n",
    "            class_scores = []\n",
    "            for c in self.classes:\n",
    "                word_prob = self.parameters[c]['word_prob']\n",
    "                log_prob = self.parameters[c]['prior']\n",
    "                \n",
    "                common_words = np.isin(word_prob.nonzero()[1], x.nonzero()[1])\n",
    "                \n",
    "                x = x[:, common_words]\n",
    "                word_prob_common = word_prob[:, common_words]\n",
    "            \n",
    "                log_prob += np.sum(np.sum(np.multiply(x, word_prob_common)))\n",
    "                class_scores.append(log_prob)\n",
    "            results.append(self.classes[np.argmax(class_scores)]) \n",
    "        return np.array(results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Bag of Words Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnb_evaluate(X_train, y_train, X_test, y_test, name):\n",
    "    mbn = MultinomialNaiveBayes()\n",
    "    mbn.train(X_train, y_train)\n",
    "    predictions = mbn.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "\n",
    "    print(f'Multinomial Naive Bayes Results on {name} Dataset')\n",
    "    print(f'Accuracy = {acc}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Recall = {recall}')\n",
    "    print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Results on Enron 1 Dataset\n",
      "Accuracy = 0.6776315789473685\n",
      "Precision = 0.7010050251256281\n",
      "Recall = 0.9087947882736156\n",
      "F1 score = 0.7914893617021277\n"
     ]
    }
   ],
   "source": [
    "mnb_evaluate(e1_Xtrain_bow, e1_ytrain_bow, e1_Xtest_bow, e1_ytest_bow, 'Enron 1') # approx 3 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Results on Enron 2 Dataset\n",
      "Accuracy = 0.7238493723849372\n",
      "Precision = 0.7523364485981309\n",
      "Recall = 0.9252873563218391\n",
      "F1 score = 0.8298969072164949\n"
     ]
    }
   ],
   "source": [
    "mnb_evaluate(e2_Xtrain_bow, e2_ytrain_bow, e2_Xtest_bow, e2_ytest_bow, 'Enron 2') # approx 3 secs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Results on Enron 4 Dataset\n",
      "Accuracy = 0.27992633517495397\n",
      "Precision = 0.27992633517495397\n",
      "Recall = 1.0\n",
      "F1 score = 0.4374100719424461\n"
     ]
    }
   ],
   "source": [
    "mnb_evaluate(e4_Xtrain_bow, e4_ytrain_bow, e4_Xtest_bow, e4_ytest_bow, 'Enron 4') # approx 4 secs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Discrete Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteNaiveBayes:\n",
    "    def train(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.probabilities = {}\n",
    "        self.prior = {}\n",
    "        self.features = X.shape[1]\n",
    "        \n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.prior[c] = np.log(X_c.shape[0] / X.shape[0])\n",
    "            \n",
    "            p = np.log((X_c.sum(axis = 0) + add_one )/ (X_c.sum() + 2))\n",
    "            self.probabilities[c] = p\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        X = X[:, : self.features]\n",
    "        X = X.toarray()\n",
    "        for x in X: \n",
    "            class_scores = []\n",
    "            for c in self.classes:\n",
    "                p = self.probabilities[c]\n",
    "                prior = self.prior[c]\n",
    "                p = np.asarray(p).flatten()\n",
    "                if len(p) > len(x):\n",
    "                    diff = len(p) - len(x)\n",
    "                    x = np.pad(x, (0, diff), 'constant')\n",
    "                posterior = prior + ((x * p) + ((1 - x) * (1 - p))).sum()\n",
    "                class_scores.append(posterior)\n",
    "                     \n",
    "            results.append(self.classes[np.argmax(class_scores)])\n",
    "        return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Bernoulli Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnb_evaluate(X_train, y_train, X_test, y_test, name):\n",
    "    dnb = DiscreteNaiveBayes()\n",
    "    dnb.train(X_train, y_train)\n",
    "    predictions = dnb.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "\n",
    "    print(f'Discrete Naive Bayes Results on {name} Dataset')\n",
    "    print(f'Accuracy = {acc}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Recall = {recall}')\n",
    "    print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Naive Bayes Results on Enron 1 Dataset\n",
      "Accuracy = 0.6732456140350878\n",
      "Precision = 0.6732456140350878\n",
      "Recall = 1.0\n",
      "F1 score = 0.8047182175622543\n"
     ]
    }
   ],
   "source": [
    "dnb_evaluate(e1_Xtrain_bli, e1_ytrain_bli, e1_Xtest_bli, e1_ytest_bli, 'Enron 1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Naive Bayes Results on Enron 2 Dataset\n",
      "Accuracy = 0.7280334728033473\n",
      "Precision = 0.7280334728033473\n",
      "Recall = 1.0\n",
      "F1 score = 0.8426150121065376\n"
     ]
    }
   ],
   "source": [
    "dnb_evaluate(e2_Xtrain_bli, e2_ytrain_bli, e2_Xtest_bli, e2_ytest_bli, 'Enron 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Naive Bayes Results on Enron 4 Dataset\n",
      "Accuracy = 0.7200736648250461\n",
      "Precision = 0.0\n",
      "Recall = 0.0\n",
      "F1 score = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dnb_evaluate(e4_Xtrain_bli, e4_ytrain_bli, e4_Xtest_bli, e4_ytest_bli, 'Enron 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, l2 = 0.1):\n",
    "        self.weights = None\n",
    "        self.num_features = None\n",
    "        self.lambda_ = l2\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def gradient(self, X, y, h):\n",
    "        m = len(y)\n",
    "        return (np.dot(X.T, (y - h)) / m) - ((self.lambda_ * np.concatenate([[0], self.weights[1:]])) / m)\n",
    "\n",
    "    def loss(self, y, h, weights):\n",
    "        m = len(y)\n",
    "        return np.mean(y * np.log(h + 10**-9) + (1 - y) * np.log(1 - h + 10**-9)) - (self.lambda_ * np.sum(weights[1:] ** 2) / 2)\n",
    "\n",
    "    def train(self, X, y, learning_rate = 0.01, max_iter = 10000):\n",
    "        X = X.toarray()\n",
    "        self.num_features = X.shape[1]\n",
    "        X = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            z = np.dot(X, self.weights)\n",
    "            pred = self.sigmoid(z)\n",
    "            loss = self.loss(y, pred, self.weights)\n",
    "            grad = self.gradient(X, y, pred)\n",
    "            self.weights += learning_rate * grad # gradient ascent \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.toarray()\n",
    "        X = X[:,:self.num_features]\n",
    "\n",
    "        if X.shape[1] < len(self.weights):\n",
    "            self.weights = self.weights[:X.shape[1]+1]\n",
    "        z = np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "        y_pred = self.sigmoid(z)\n",
    "        return np.round(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [0.001, 0.01, 0.1, 1]\n",
    "def cross_validation(X, y, grid):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 42) # 70/30 train validation split\n",
    "    best_f1 = 0 \n",
    "    lambda_ = None\n",
    "    \n",
    "    for l in grid: # train LR using each value of lambda\n",
    "        lr = LogisticRegression(l2 = l) \n",
    "        lr.train(X_train, y_train, max_iter = 5000)\n",
    "        pred = lr.predict(X_val)\n",
    "\n",
    "        f1 = f1_score(y_val, pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            lambda_ = l\n",
    "\n",
    "    return lambda_\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_evaluate(X_train, y_train, X_test, y_test, name):\n",
    "    lambda_ = cross_validation(X_train, y_train, grid)\n",
    "\n",
    "    lr = LogisticRegression(l2 = lambda_)\n",
    "    lr.train(X_train, y_train, max_iter = 10000)\n",
    "    predictions = lr.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "\n",
    "    print(f'Logistic Regresstion Results on {name} Dataset')\n",
    "    print(f'Accuracy = {acc}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Recall = {recall}')\n",
    "    print(f'F1 score = {f1}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 1 BOW Dataset\n",
      "Accuracy = 0.43201754385964913\n",
      "Precision = 0.7727272727272727\n",
      "Recall = 0.22149837133550487\n",
      "F1 score = 0.34430379746835443\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e1_Xtrain_bow, e1_ytrain_bow, e1_Xtest_bow, e1_ytest_bow, 'Enron 1 BOW') # approx 30 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 1 Bernoulli Dataset\n",
      "Accuracy = 0.41228070175438597\n",
      "Precision = 0.7407407407407407\n",
      "Recall = 0.19543973941368079\n",
      "F1 score = 0.3092783505154639\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e1_Xtrain_bli, e1_ytrain_bli, e1_Xtest_bli, e1_ytest_bli, 'Enron 1 Bernoulli') # approx 30 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 2 BOW Dataset\n",
      "Accuracy = 0.4497907949790795\n",
      "Precision = 0.8102189781021898\n",
      "Recall = 0.31896551724137934\n",
      "F1 score = 0.45773195876288664\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e2_Xtrain_bow, e2_ytrain_bow, e2_Xtest_bow, e2_ytest_bow, 'Enron 2 BOW') # approx 35 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 2 Bernoulli Dataset\n",
      "Accuracy = 0.5209205020920502\n",
      "Precision = 0.7741935483870968\n",
      "Recall = 0.4827586206896552\n",
      "F1 score = 0.5946902654867257\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e2_Xtrain_bli, e2_ytrain_bli, e2_Xtest_bli, e2_ytest_bli, 'Enron 2 Bernoulli') # approx 35 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 4 BOW Dataset\n",
      "Accuracy = 0.7182320441988951\n",
      "Precision = 0.0\n",
      "Recall = 0.0\n",
      "F1 score = 0.0\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e4_Xtrain_bow, e4_ytrain_bow, e4_Xtest_bow, e4_ytest_bow, 'Enron 4 BOW') # approx 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 4 Bernoulli Dataset\n",
      "Accuracy = 0.7200736648250461\n",
      "Precision = 0.0\n",
      "Recall = 0.0\n",
      "F1 score = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate(e4_Xtrain_bli, e4_ytrain_bli, e4_Xtest_bli, e4_ytest_bli, 'Enron 4 Bernoulli') # approx 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifer from scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def sgd_eval(X_train, y_train, X_test, y_test, name):\n",
    "    sgd = SGDClassifier(max_iter=5000)\n",
    "\n",
    "    param_grid = {\n",
    "        'loss': ['hinge', 'log_loss', 'modified_huber'],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(sgd, param_grid, cv = 5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    X_test.resize((X_test.shape[0], X_train.shape[1]))\n",
    "\n",
    "    predictions = best_estimator.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "\n",
    "    print(f'Logistic Regresstion Results on {name} Dataset')\n",
    "    print(f'Accuracy = {acc}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Recall = {recall}')\n",
    "    print(f'F1 score = {f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 1 BOW Dataset\n",
      "Accuracy = 0.5087719298245614\n",
      "Precision = 0.6666666666666666\n",
      "Recall = 0.5407166123778502\n",
      "F1 score = 0.5971223021582733\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e1_Xtrain_bow, e1_ytrain_bow, e1_Xtest_bow, e1_ytest_bow, 'Enron 1 BOW') # all are approx 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 1 Bernoulli Dataset\n",
      "Accuracy = 0.5109649122807017\n",
      "Precision = 0.7164948453608248\n",
      "Recall = 0.4527687296416938\n",
      "F1 score = 0.5548902195608783\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e1_Xtrain_bli, e1_ytrain_bli, e1_Xtest_bli, e1_ytest_bli, 'Enron 1 Bernoulli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 2 BOW Dataset\n",
      "Accuracy = 0.4100418410041841\n",
      "Precision = 0.7704918032786885\n",
      "Recall = 0.27011494252873564\n",
      "F1 score = 0.4\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e2_Xtrain_bow, e2_ytrain_bow, e2_Xtest_bow, e2_ytest_bow, 'Enron 2 BOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 2 Bernoulli Dataset\n",
      "Accuracy = 0.3619246861924686\n",
      "Precision = 0.7415730337078652\n",
      "Recall = 0.1896551724137931\n",
      "F1 score = 0.3020594965675057\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e2_Xtrain_bli, e2_ytrain_bli, e2_Xtest_bli, e2_ytest_bli, 'Enron 2 Bernoulli') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 4 BOW Dataset\n",
      "Accuracy = 0.6703499079189686\n",
      "Precision = 0.23529411764705882\n",
      "Recall = 0.07894736842105263\n",
      "F1 score = 0.11822660098522168\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e4_Xtrain_bow, e4_ytrain_bow, e4_Xtest_bow, e4_ytest_bow, 'Enron 4 BOW') # approx 3 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresstion Results on Enron 4 Bernoulli Dataset\n",
      "Accuracy = 0.7090239410681399\n",
      "Precision = 0.4858490566037736\n",
      "Recall = 0.6776315789473685\n",
      "F1 score = 0.565934065934066\n"
     ]
    }
   ],
   "source": [
    "sgd_eval(e4_Xtrain_bli, e4_ytrain_bli, e4_Xtest_bli, e4_ytest_bli, 'Enron 4 Bernoulli') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
